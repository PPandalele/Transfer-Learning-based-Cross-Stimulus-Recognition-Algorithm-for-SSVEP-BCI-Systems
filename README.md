å¥½çš„ï¼Œæˆ‘å·²ç»ç»“åˆä½ æä¾›çš„è®ºæ–‡å†…å®¹å’Œæ‰€æœ‰æ ¸å¿ƒä»£ç æ–‡ä»¶ï¼Œæ•´ç†äº†ä¸€ä»½å¯ä»¥ç›´æ¥æ”¾åˆ° GitHub çš„ **è¯¦ç»† README.md**ï¼ŒåŒ…å«æ ‡é¢˜ã€ç®€ä»‹ã€åŠŸèƒ½è¯´æ˜ã€ç³»ç»Ÿç»“æ„ã€ä½¿ç”¨æ–¹æ³•å’Œå¼•ç”¨ç­‰ï¼Œæ’ç‰ˆé‡‡ç”¨æ ‡å‡† Markdownï¼ˆ`#`ã€`##` ç­‰ï¼‰ã€‚ä½ å¤åˆ¶åç›´æ¥ä½œä¸º `README.md` æ–‡ä»¶å³å¯ã€‚

---

# Transfer-Learning-based Cross-Stimulus Recognition Algorithm for SSVEP-BCI Systems

This repository provides the **implementation and system code** for my MSc dissertation:
**â€œTransfer Learning-based Cross-Stimulus Recognition Algorithm for SSVEP-BCI Systemsâ€ (The University of Manchester, 2023)**.

It includes:

* A **real-time BCI speller system** with GUI (Beta simulation, Online test, Demo).
* **TLCCA (Transfer Learning-based CCA)** training, testing, and recognition pipelines.
* **Offline comparison of eight SSVEP algorithms** on **Benchmark** and **BETA** datasets.

---

## âœ¨ Key Features

* **Three GUI Modes (pygame-based)**

  * **Beta simulation**: dataset-driven real-time recognition (with `simulation.py` / `gui.py`).
  * **Online real-time**: connects to EEG device and performs live recognition (`gui_bci.py` + `eeg_processor.py`).
  * **Demo mode**: simplified single-window demo.

* **TLCCA Real-Time Engine**

  * Filter-bank analysis (coefficients follow $n^{-1.25}+0.25$)
  * Standard SSVEP harmonics, adaptive time windows.
  * Cross-stimulus transfer across different frequencies.

* **Trainer & Extractor**

  * `extract block.py`: train TLCCA models for BETA subjects (per subject/block/time-window).
  * Generates `.mat` model files + corresponding test datasets.

* **CLI Real-Time Runner**

  * `try222.py`: lightweight command-line runner, supports subject/block/time-window selection.
  * No GUI required.

* **Offline Algorithm Comparison**

  * `modify_lele.docx` (dissertation) & included MATLAB/Python codes implement **8 methods**:

    * CCA, eCCA, ms-eCCA, eTRCA, ms-eTRCA, TDCA, tlCCA-1, tlCCA-2
  * Results validated on **Benchmark (35 subjects)** and **BETA (70 subjects)** datasets.

---

## ğŸ“‚ Repository Structure

```
.
â”œâ”€â”€ gui.py              # GUI speller (with experimenter/participant dual interface)
â”œâ”€â”€ gui_bci.py          # GUI for BETA dataset & online test
â”œâ”€â”€ simulation.py       # GUI in simulation mode
â”œâ”€â”€ eeg processor.py    # Real-time TLCCA recognition engine (for GUI mode)
â”œâ”€â”€ try222.py           # CLI real-time recognition (no GUI)
â”œâ”€â”€ extract block.py    # TLCCA trainer + test data extractor
â”œâ”€â”€ modify_lele.docx    # MSc dissertation (system description + experiments)
```

---

## ğŸš€ Usage

### 1. Environment

* Python 3.8+
* Required packages:

  ```bash
  pip install numpy scipy scikit-learn pygame pandas
  ```

### 2. Train Models & Extract Data

```bash
python extract\ block.py
```

This will generate:

* `tlcca_models/S{subject}_tlcca_model_exclude_{block}.mat`
* `test_data/S{subject}_blocks_{block}_test_data.mat`

### 3. Run CLI Real-Time Recognition

```bash
python try222.py
```

* Select subject, block, and time window length (0.3sâ€“1.2s).
* Loads model & test data, performs recognition in terminal.

### 4. Run GUI System

```bash
python gui.py
```

Modes available:

* **Speller beta dataset simulation**
* **Speller online test**
* **Speller demo**

For online test, ensure EEG hardware connection and correct COM settings.

### 5. Real-Time Recognition with GUI

`eeg processor.py` is automatically loaded by `gui_bci.py` when EEG recognition starts.

---

## ğŸ“Š Experimental Results

* Large-scale validation on **Benchmark (35 subjects)** and **BETA (70 subjects)**.
* TLCCA achieved significant improvements in:

  * Recognition accuracy
  * Information transfer rate (ITR)

Detailed results and figures are in the dissertation (`modify_lele.docx`).

---

## ğŸ“– Reference

This implementation is based on the work of:

```bibtex
@article{wong2021transferring,
  title={Transferring subject-specific knowledge across stimulus frequencies in SSVEP-based BCIs},
  author={Wong, Chi Man and Wang, Ze and Rosa, Agostinho C and Chen, CL Philip and Jung, Tzyy-Ping and Hu, Yong and Wan, Feng},
  journal={IEEE Transactions on Automation Science and Engineering},
  volume={18},
  number={2},
  pages={552--563},
  year={2021},
  publisher={IEEE}
}
```

Original reference code and materials:

* `E:\Dropbox\Disk\BCI competition 2019\ssvep-training-local-system-for-matlab\my\paper_ssvep_acc_dataset_transfer_als_20190930.m`
* `E:\Dropbox\Disk\BCI competition 2019\ssvep-training-local-system-for-matlab\my\paper_data_transfer_result_20190930.xlsx`

Prepared by **Chi Man Wong** ([chiman465@gmail.com](mailto:chiman465@gmail.com)), Date: 22 June 2022.

---

## ğŸ“Œ Notes

* If you use this code for academic publication, **please cite Wong et al. (2021)**.
* This repository extends their work by:

  * Adding **GUI interfaces**
  * Implementing **real-time TLCCA recognition**
  * Providing a **full experimental BCI speller system**

---

è¦ä¸è¦æˆ‘å¸®ä½ åœ¨ README é‡ŒåŠ ä¸Š **è¿è¡Œç¤ºä¾‹æˆªå›¾ï¼ˆGUIç•Œé¢å’Œç»ˆç«¯è¿è¡Œæ•ˆæœï¼‰** çš„å ä½ç¬¦ï¼Ÿè¿™æ ·æ”¾åˆ° GitHub ä¸Šä¼šæ›´ç›´è§‚ã€‚
